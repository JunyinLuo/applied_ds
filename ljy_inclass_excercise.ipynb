{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b389d61-19f2-413c-818c-5301ce2550c4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## workshop for ljy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8d6e412-9888-4b16-82ab-7e5ec3b4bfb7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_pit_stop = spark.read.csv('s3://columbia-gr5069-main/raw/lap_times.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9ec170d-8ff3-4766-a4bc-ce4eb61d5516",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_pit_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c11e4f0c-d49e-419d-910c-475e510862a1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_driver = spark.read.csv('s3://columbia-gr5069-main/raw/drivers.csv',header=True)\n",
    "df_driver.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b959c7e2-f10b-47c9-af77-870f227e46ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cddd08de-c65c-44d1-bc91-288d070f0d11",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa0db674-f95f-402d-8cb1-1f360a1d97bf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, datediff, current_date\n",
    "from pyspark.sql.types import IntegerType  # Import IntegerType\n",
    "\n",
    "df_driver = df_driver.withColumn(\"age\", datediff(current_date(),df_driver.dob)/365)\n",
    "\n",
    "df_driver = df_driver.withColumn('age', df_driver['age'].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cebe9127-f04d-4a1e-bf9d-2f73f4789cc1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1057528c-04ac-4cf9-90a9-6ee7e1c5b169",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_lap_drivers = df_driver.join(df_laptimes, on = ['driverId'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39eea629-e449-471f-9a1c-2f371546f44b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_lap_drivers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd21085a-0865-4408-9152-6264d488d558",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_lap_drivers = df_driver.select('driverId','nationality','age').join(df_laptimes, on = ['driverId'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "091e6de8-3c75-4b07-9c0b-6f922301ce60",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_lap_drivers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01d6d9b4-8dea-4ba9-881a-c7b4ce331a0b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### agggregate age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e53eb9b-4644-40d0-a52c-89a6288645d3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, avg\n",
    "df_lap_drivers = df_lap_drivers.groupBy('nationality','age').agg(avg('milliseconds'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e2e543f-70f6-4879-8ded-0a6165b75bef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_lap_drivers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e4653e6-7436-4f72-9aaa-1ae717a7f9b3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### storing data in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a91fba4-2663-42a6-8e27-d357273b796f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_lap_drivers.write.csv('s3://jl6530-gr5069/processed//inclass/laptimes_by_drivers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5dd34ca-b161-45c7-89d1-ef180aecf296",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b397ead-f40d-4e4a-b5ec-c41d8b011240",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3e399db-6570-4bc4-819a-2300d310d777",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_pit_stop = spark.read.csv('s3://columbia-gr5069-main/raw/pit_stops.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e008fd5-27a9-417a-829d-aed7b5dc9c0e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bucket = \"s3://columbia-gr5069-main/raw/\"\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, datediff, current_date\n",
    "from pyspark.sql.types import IntegerType \n",
    "from pyspark.sql.functions import col, avg, sum, count, when, isnan, lit, round\n",
    "from pyspark.sql.functions import col, upper, when, substring, regexp_replace, translate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1d85137-ae1f-4bf4-92ac-c101179857f0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a903ada6-3f4d-4c07-8226-91455001521f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "482d2bb8-56e0-4ab1-b629-8d43fcd4892e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_pit_stop = df_pit_stop.withColumn(\"driverId\", col(\"driverId\").cast(IntegerType()))\n",
    "df_pit_stop = df_pit_stop.withColumn(\"raceId\", col(\"raceId\").cast(IntegerType()))\n",
    "\n",
    "# 重命名df_pit_stop中的'milliseconds'列\n",
    "df_pit_stop = df_pit_stop.withColumnRenamed(\"milliseconds\", \"pitStopMilliseconds\")\n",
    "\n",
    "\n",
    "# 重命名df_pit_stop中的'time'列（如果需要）\n",
    "df_pit_stop = df_pit_stop.withColumnRenamed(\"time\", \"pitStopTime\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e100cbf3-2535-4562-a10d-bdee948ff43e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_pit_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca93d798-67ce-4c49-8589-9c2856936b1b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "selected_columns = ['driverId', 'raceId',  'stop', 'duration']\n",
    "\n",
    "df_final_selected = df_pit_stop.select(*selected_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41f0640c-6465-434b-99c2-72629418dff4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 可能需要安装MLflow\n",
    "# pip install mlflow\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b34c0de3-54fb-4f4d-a55a-a98f5b191f97",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_extract, col\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 首先确保 `duration` 列存在并转换为数值类型\n",
    "df_final_selected = df_final_selected.withColumn(\"durationSeconds\", regexp_extract(col(\"duration\"), \"(\\d+\\.\\d+)\", 1).cast(\"float\"))\n",
    "\n",
    "# 由于之前的操作已经在 PySpark DataFrame 上执行，现在可以安全地转换为 Pandas DataFrame\n",
    "pdf_final_selected = df_final_selected.toPandas()\n",
    "\n",
    "# 准备用于训练的数据\n",
    "X = pdf_final_selected.drop(['durationSeconds'], axis=1)\n",
    "y = pdf_final_selected['durationSeconds'].astype(float)  # 确保 durationSeconds 是浮点类型\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 查找和替换 '\\\\N' 值\n",
    "X_train = X_train.replace('\\\\N', np.nan)\n",
    "y_train = y_train.replace('\\\\N', np.nan)\n",
    "\n",
    "X_test = X_test.replace('\\\\N', np.nan)\n",
    "y_test = y_test.replace('\\\\N', np.nan)\n",
    "# 处理缺失值\n",
    "# 选项 1: 移除包含缺失值的行\n",
    "X_train = X_train.dropna()\n",
    "y_train = y_train.dropna()\n",
    "\n",
    "X_test = X_test.dropna()\n",
    "y_test = y_test.dropna()\n",
    "# 选择 X_train 中的数值型列并转换为 float 类型\n",
    "X_train_numeric = X_train.select_dtypes(include=[np.number])\n",
    "X_train = X_train_numeric.astype(float)\n",
    "\n",
    "X_test_numeric = X_test.select_dtypes(include=[np.number])\n",
    "X_test = X_test_numeric.astype(float)\n",
    "# 将 y_train 转换为 float 类型\n",
    "y_train = y_train.astype(float)\n",
    "y_test = y_test.astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "683a0d01-e4d0-4ff5-9998-6b1c24c6e7c9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "with mlflow.start_run(run_name=\"Basic RF Experiment\") as run:\n",
    "  # Create model, train it, and create predictions\n",
    "  rf = RandomForestRegressor()\n",
    "  rf.fit(X_train, y_train)\n",
    "  predictions = rf.predict(X_test)\n",
    "  \n",
    "  # Log model\n",
    "  mlflow.sklearn.log_model(rf, \"random-forest-model\")\n",
    "  \n",
    "  # Create metrics\n",
    "  mse = mean_squared_error(y_test, predictions)\n",
    "  print(\"  mse: {}\".format(mse))\n",
    "  \n",
    "  # Log metrics\n",
    "  mlflow.log_metric(\"mse\", mse)\n",
    "  \n",
    "  runID = run.info.run_uuid\n",
    "  experimentID = run.info.experiment_id\n",
    "  \n",
    "  print(\"Inside MLflow Run with run_id {} and experiment_id {}\".format(runID, experimentID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34a8a234-e861-418e-b212-bae9f2c5243d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def log_rf(experimentID, run_name, params, X_train, X_test, y_train, y_test):\n",
    "  import os\n",
    "  import matplotlib.pyplot as plt\n",
    "  import mlflow.sklearn\n",
    "  import seaborn as sns\n",
    "  from sklearn.ensemble import RandomForestRegressor\n",
    "  from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "  import tempfile\n",
    "  import pandas as pd\n",
    "\n",
    "  with mlflow.start_run(experiment_id=experimentID, run_name=run_name) as run:\n",
    "    # Create model, train it, and create predictions\n",
    "    rf = RandomForestRegressor(**params)\n",
    "    rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "\n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(rf, \"random-forest-model\")\n",
    "\n",
    "    # Log params\n",
    "    [mlflow.log_param(param, value) for param, value in params.items()]\n",
    "\n",
    "    # Create metrics\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    print(\"  mse: {}\".format(mse))\n",
    "    print(\"  mae: {}\".format(mae))\n",
    "    print(\"  R2: {}\".format(r2))\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "    # Create feature importance\n",
    "    importance = pd.DataFrame(list(zip(X_train.columns, rf.feature_importances_)),\n",
    "                              columns=[\"Feature\", \"Importance\"]\n",
    "                             ).sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "    # Log importances using a temporary file\n",
    "    temp = tempfile.NamedTemporaryFile(prefix=\"feature-importance-\", suffix=\".csv\", delete=False)\n",
    "    temp_name = temp.name\n",
    "    try:\n",
    "      importance.to_csv(temp_name, index=False)\n",
    "      mlflow.log_artifact(temp_name, \"feature-importance.csv\")\n",
    "    finally:\n",
    "      temp.close()  # Delete the temp file\n",
    "\n",
    "    # Create plot for residuals\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.residplot(x=predictions, y=y_test - predictions, lowess=True)\n",
    "    plt.xlabel(\"Predicted values\")\n",
    "    plt.ylabel(\"Residuals\")\n",
    "    plt.title(\"Residual Plot\")\n",
    "\n",
    "    # Log residuals using a temporary file\n",
    "    temp = tempfile.NamedTemporaryFile(prefix=\"residuals-\", suffix=\".png\", delete=False)\n",
    "    temp_name = temp.name\n",
    "    try:\n",
    "      fig.savefig(temp_name)\n",
    "      mlflow.log_artifact(temp_name, \"residuals.png\")\n",
    "    finally:\n",
    "      temp.close()  # Delete the temp file\n",
    "\n",
    "    return run.info.run_uuid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "286265b1-0c95-4472-ad85-474d62a0007c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "  \"n_estimators\": 100,\n",
    "  \"max_depth\": 6,\n",
    "  \"random_state\": 42\n",
    "}\n",
    "\n",
    "log_rf(experimentID, \"Second Run\", params, X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ljy_inclass_excercise",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
